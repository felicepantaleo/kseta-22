
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-8.2.1">
    
    
      
        <title>Introduction to CUDA - Introduction to Parallel Programming</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.e8d9bf0c.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.e6a45f82.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#exercise-1-cuda-memory-model" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Introduction to Parallel Programming" class="md-header__button md-logo" aria-label="Introduction to Parallel Programming" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Introduction to Parallel Programming
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Introduction to CUDA
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Introduction to Parallel Programming" class="md-nav__button md-logo" aria-label="Introduction to Parallel Programming" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Introduction to Parallel Programming
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Welcome to the Introduction to parallel programming course
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Parallelism
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Parallelism" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Parallelism
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../1_parcpp/" class="md-nav__link">
        Parallel C++ and TBB
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Introduction to CUDA
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Introduction to CUDA
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#exercise-1-cuda-memory-model" class="md-nav__link">
    Exercise 1. CUDA Memory Model
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercise-2-launch-a-kernel" class="md-nav__link">
    Exercise 2. Launch a kernel
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercise-3-two-dimensional-grid" class="md-nav__link">
    Exercise 3. Two-dimensional grid
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercise-4-measuring-throughput" class="md-nav__link">
    Exercise 4. Measuring throughput
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercise-5-parallel-reduction" class="md-nav__link">
    Exercise 5. Parallel Reduction
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenge-histogram" class="md-nav__link">
    Challenge: Histogram
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#utility-measuring-time-using-cuda-events" class="md-nav__link">
    Utility. Measuring time using CUDA Events
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#atomics-1" class="md-nav__link">
    Atomics [1]
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Setup
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Setup" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Setup
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../setup/Setup/" class="md-nav__link">
        Setup
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#exercise-1-cuda-memory-model" class="md-nav__link">
    Exercise 1. CUDA Memory Model
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercise-2-launch-a-kernel" class="md-nav__link">
    Exercise 2. Launch a kernel
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercise-3-two-dimensional-grid" class="md-nav__link">
    Exercise 3. Two-dimensional grid
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercise-4-measuring-throughput" class="md-nav__link">
    Exercise 4. Measuring throughput
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#exercise-5-parallel-reduction" class="md-nav__link">
    Exercise 5. Parallel Reduction
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenge-histogram" class="md-nav__link">
    Challenge: Histogram
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#utility-measuring-time-using-cuda-events" class="md-nav__link">
    Utility. Measuring time using CUDA Events
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#atomics-1" class="md-nav__link">
    Atomics [1]
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                


  <h1>Introduction to CUDA</h1>

<p>The CUDA Runtime API reference manual is a very useful source of information:
<a href="http://docs.nvidia.com/cuda/cuda-runtime-api/index.html" target="_blank">http://docs.nvidia.com/cuda/cuda-runtime-api/index.html</a></p>
<pre><code class="language-bash">$ cd kseta-22/hands-on/cuda-exercises
</code></pre>
<p>Check that your environment is correctly configured to compile CUDA code by running:</p>
<pre><code class="language-bash">$ nvcc --version
</code></pre>
<p>Compile and run the <code>deviceQuery</code> application:</p>
<pre><code class="language-bash">cd kseta-22/hands-on/cuda-exercises/utils/deviceQuery
make
</code></pre>
<p>You can get some useful information about the features and the limits that you will find on the device you will be running your code on. For example:</p>
<pre><code>$ ./deviceQuery 
./deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: &quot;Tesla V100-SXM2-32GB&quot;
  CUDA Driver Version / Runtime Version          11.4 / 11.4
  CUDA Capability Major/Minor version number:    7.0
  Total amount of global memory:                 32510 MBytes (34089730048 bytes)
  (80) Multiprocessors, ( 64) CUDA Cores/MP:     5120 CUDA Cores
  GPU Max Clock rate:                            1530 MHz (1.53 GHz)
  Memory Clock rate:                             877 Mhz
  Memory Bus Width:                              4096-bit
  L2 Cache Size:                                 6291456 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)
  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total shared memory per multiprocessor:        98304 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 6 copy engine(s)
  Run time limit on kernels:                     Yes
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Enabled
  Device supports Unified Addressing (UVA):      Yes
  Device supports Managed Memory:                Yes
  Device supports Compute Preemption:            Yes
  Supports Cooperative Kernel Launch:            Yes
  Supports MultiDevice Co-op Kernel Launch:      Yes
  Device PCI Domain ID / Bus ID / location ID:   0 / 58 / 0
  Compute Mode:
     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.4, CUDA Runtime Version = 11.4, NumDevs = 1
Result = PASS
</code></pre>
<p>Some of you are sharing the same machine and some time measurements can be influenced by other users running at the very same moment. It can be necessary to run time measurements multiple times.</p>
<h3 id="exercise-1-cuda-memory-model">Exercise 1. CUDA Memory Model</h3>
<p>In this exercise you will learn what heterogeneous memory model means, by demonstrating the difference between host and device memory spaces.</p>
<ol>
<li>Allocate device memory;</li>
<li>Copy the host array h_a to d_a on the device;</li>
<li>Copy the device array d_a to the device array d_b;</li>
<li>Copy the device array d_b to the host array h_a;</li>
<li>Free the memory allocated for d_a and d_b.</li>
<li>Compile and run the program by running:</li>
</ol>
<pre><code class="language-bash">$ nvcc cuda_mem_model.cu -o ex01
$ ./ex01
</code></pre>
<ul>
<li>Bonus: Measure the PCI Express bandwidth.</li>
</ul>
<h3 id="exercise-2-launch-a-kernel">Exercise 2. Launch a kernel</h3>
<p>By completing this exercise you will learn how to configure and launch a simple CUDA kernel.</p>
<ol>
<li>Allocate device memory;</li>
<li>Configure the kernel to run using a one-dimensional grid of one-dimensional blocks;</li>
<li>Each GPU thread should set one element of the array to:</li>
</ol>
<p><code>d_a[i] = blockIdx.x + threadIdx.x + 42;</code>
4. Copy the results to the host memory;
5. Check the correctness of the results</p>
<h3 id="exercise-3-two-dimensional-grid">Exercise 3. Two-dimensional grid</h3>
<p>M is a matrix of NxN integers.</p>
<ol>
<li>Set N=4</li>
<li>Write a kernel that sets each element of the matrix to its linear index (e.g. M[2,3] = 2*N + 3), by making use of two-dimensional grid and blocks. (Two-dimensional means using the x and y coordinates).</li>
<li>Copy the result to the host and check that it is correct.</li>
<li>Try with a rectangular matrix 19x67. Hint: check the kernel launch parameters.</li>
</ol>
<h3 id="exercise-4-measuring-throughput">Exercise 4. Measuring throughput</h3>
<p>The throughput of a kernel can be defined as the number of bytes read and written by a kernel in the unit of time.</p>
<p>The CUDA event API includes calls to create and destroy events, record events, and compute the elapsed time in milliseconds between two recorded events.</p>
<p>CUDA events make use of the concept of CUDA streams. A CUDA stream is simply a sequence of operations that are performed in order on the device. Operations in different streams can be interleaved and in some cases overlapped, a property that can be used to hide data transfers between the host and the device. Up to now, all operations on the GPU have occurred in the default stream, or stream 0 (also called the "Null Stream").</p>
<p>The peak theoretical throughput can be evaluated as well: if your device comes with a memory clock rate of 1GHz DDR (double data rate) and a 256-bit wide memory interface, the peak theoretical throughput can be computed with the following:</p>
<p>Throughput (GB/s)= Memory_rate(Hz) * memory_interface_width(byte) * 2 /10<sup>9</sup></p>
<ol>
<li>Compute the theoretical peak throughput of the device you are using.</li>
<li>Modify ex04.cu to give the measurement of actual throughput of the kernel.</li>
<li>Measure the throughput with a varying number of elements (in logarithmic scale). Before doing that write down what do you expect (you can also draw a diagram).</li>
<li>What did you find out? Can you give an explanation?</li>
</ol>
<h3 id="exercise-5-parallel-reduction">Exercise 5. Parallel Reduction</h3>
<p>Given an array <code>a[N]</code>, the reduction sum <code>Sum</code> of a is the sum of all its elements: <code>Sum=a[0]+a[1]+...a[N-1]</code>.
1. Implement a block-wise parallel reduction (using the shared memory).
2. For each block, save the partial sum.
3. Sum all the partial sums together.
4. Check the result comparing with the host result.
5. Measure the throughput of your reduction kernel using CUDA Events (see exercise 4)
6. Analyze your application using <code>nvvp</code>. Do you think it can be improved? How?
* Bonus: Can you implement a one-step reduction? Measure and compare the throughput of the two versions.
* Challenge: The cumulative sum of an array <code>a[N]</code> is another array <code>b[N]</code>, the sum of prefixes of <code>a</code>:
<code>b[i] = a[0] + a[1] + … + a[i]</code>. Implement a cumulative sum kernel assuming that the size of the input array is multiple of the block size.</p>
<h3 id="challenge-histogram">Challenge: Histogram</h3>
<p>The purpose of this lab is to implement an efficient histogramming algorithm for an input array of integers within a given range.</p>
<p>Each integer will map into a single bin, so the values will range from 0 to (NUM_BINS - 1).</p>
<p>The histogram bins will use unsigned 32-bit counters that must be saturated at 127 (i.e. no roll back to 0 allowed).</p>
<p>The input length can be assumed to be less than 2ˆ32. <code>NUM_BINS</code> is fixed at 4096 for this lab.
This can be split into two kernels: one that does a histogram without saturation, and a final kernel that cleans up the bins if they are too large. These two stages can also be combined into a single kernel.</p>
<h3 id="utility-measuring-time-using-cuda-events">Utility. Measuring time using CUDA Events</h3>
<pre><code class="language-C++">cudaEvent_t start, stop; float time;
cudaEventCreate(&amp;start);  cudaEventCreate(&amp;stop);
cudaEventRecord(start, 0);
square_array &lt;&lt;&lt; n_blocks, block_size &gt;&gt;&gt; (a_d, N);
cudaEventRecord(stop, 0);
cudaEventSynchronize(stop);
cudaEventElapsedTime(&amp;time, start, stop);
std::cout &lt;&lt; &quot;Time for the kernel: &quot; &lt;&lt; time &lt;&lt; &quot; ms&quot; &lt;&lt; std::endl;
</code></pre>
<h3 id="atomics-1">Atomics <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#atomic-functions" target="_blank">[1]</a></h3>
<p>An atomic function performs a read-modify-write atomic operation on one 32-bit or 64-bit word residing in global or shared memory.
The operation is atomic in the sense that it is guaranteed to be performed without interference from other threads.</p>
<pre><code class="language-C++">int atomicAdd(int* address, int val);
unsigned int atomicAdd(unsigned int* address,
                       unsigned int val);
unsigned long long int atomicAdd(unsigned long long int* address,
                                 unsigned long long int val);
float atomicAdd(float* address, float val);
double atomicAdd(double* address, double val);
__half2 atomicAdd(__half2 *address, __half2 val);
__half atomicAdd(__half *address, __half val);
</code></pre>
<p>reads the 16-bit, 32-bit or 64-bit word old located at the address address in global or shared memory, computes (old + val), and stores the result back to memory at the same address. These three operations are performed in one atomic transaction. The function returns old.</p>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../1_parcpp/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Parallel C++ and TBB" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Parallel C++ and TBB
            </div>
          </div>
        </a>
      
      
        
        <a href="../../setup/Setup/" class="md-footer__link md-footer__link--next" aria-label="Next: Setup" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Setup
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../../assets/javascripts/workers/search.bd0b6b67.min.js"}</script>
    
    
      <script src="../../assets/javascripts/bundle.8aa65030.min.js"></script>
      
    
  </body>
</html>